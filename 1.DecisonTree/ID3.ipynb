{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[list.sort() vs sorted()](https://docs.python.org/3/howto/sorting.html#sortinghowto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3:\n",
    "    def createDataSet(self):\n",
    "        dataSet = [[1, 1, 'yes'],\n",
    "                   [1, 1, 'yes'],\n",
    "                   [1, 0, 'no'],\n",
    "                   [0, 1, 'no'],\n",
    "                   [0, 1, 'no']]\n",
    "        labels = ['no surfacing', 'flippers']\n",
    "        return dataSet, labels\n",
    "    \n",
    "    def calcShannonEnt(self, dataSet):\n",
    "        \"\"\"Calculate the Shannon entropy of a dataset.\n",
    "\n",
    "        :param dataSet: The dataset needs to calculated.\n",
    "        \"\"\"\n",
    "        numEntries = len(dataSet)\n",
    "        labelCounts = {}\n",
    "        for featVec in dataSet:\n",
    "            currentLabel = featVec[-1]\n",
    "            if currentLabel not in labelCounts.keys():\n",
    "                labelCounts[currentLabel] = 0\n",
    "            labelCounts[currentLabel] += 1\n",
    "        shannonEnt = -sum([(value / numEntries) * log((value / numEntries), 2) \n",
    "                           for value in labelCounts.values()])\n",
    "        return shannonEnt\n",
    "\n",
    "    def cond_entropy(self, dataset, feature_idx):\n",
    "        \"\"\"Calculate the weighted entropy of several sub datasets.\n",
    "\n",
    "        :param dataset: The raw dataset\n",
    "        :param feature_idx: The index of feature splited the dataset.\n",
    "        \"\"\"\n",
    "        dataset_size = len(dataset)\n",
    "        sub_datasets = {}\n",
    "        for data in dataset:\n",
    "            feature_value = data[feature_idx]\n",
    "            if feature_value not in sub_datasets:\n",
    "                sub_datasets[feature_value] = []\n",
    "            sub_datasets[feature_value].append(data)\n",
    "        # Sub dataset's weighted entropy\n",
    "        cond_entropy = sum([(len(sub_dataset) / dataset_size) * cal_entropy(sub_dataset) \n",
    "                            for sub_dataset in sub_datasets.values()])\n",
    "        return cond_entropy\n",
    "\n",
    "    def info_gain(self, entropy, cond_entropy):\n",
    "        return entropy - cond_entropy\n",
    "\n",
    "    def splitDataSet(self, dataSet, axis, value):\n",
    "        \"\"\"Dataset splitting on a given feature.\n",
    "        \n",
    "        :param axis: The index of the specified feature.\n",
    "        :param value: The value of the specified feature.\n",
    "        \"\"\"\n",
    "        retDataSet = []\n",
    "        for featVec in dataSet:\n",
    "            if featVec[axis] == value:\n",
    "                # dropping the column of the feature.\n",
    "                reducedFeatVec = featVec[: axis]\n",
    "                reducedFeatVec.extend(featVec[axis + 1 :])\n",
    "                retDataSet.append(reducedFeatVec)\n",
    "        return retDataSet\n",
    "    \n",
    "    def chooseBestFeatureToSplit(self, dataSet):\n",
    "        \"\"\"Choose best  feature to split.\n",
    "        \n",
    "        :return bestFeature: The index of the best feature to split on.\n",
    "        \"\"\"\n",
    "        numFeatures = len(dataSet[0]) - 1\n",
    "        baseEntropy = self.calcShannonEnt(dataSet)\n",
    "        bestInfoGain = 0.0\n",
    "        bestFeature = -1\n",
    "        for i in range(numFeatures):\n",
    "            # Create unique list of class labels.\n",
    "            featList = [example[i] for example in dataSet]\n",
    "            uniqueVals = set(featList)\n",
    "            # Calculate entropy for each split subdataset.\n",
    "            weightedEntropy = 0.0\n",
    "            for value in uniqueVals:\n",
    "                subDataSet = self.splitDataSet(dataSet, i, value)\n",
    "                prob = len(subDataSet) / len(dataSet)\n",
    "                weightedEntropy += prob * self.calcShannonEnt(subDataSet)\n",
    "            infoGain = baseEntropy - weightedEntropy\n",
    "            # Find the best information gain\n",
    "            if infoGain > bestInfoGain:\n",
    "                bestInfoGain = infoGain\n",
    "                bestFeature = i\n",
    "        return bestFeature\n",
    "    \n",
    "    def majorityCnt(classList):\n",
    "        \"\"\"Find the class that occurs with the greatest frequency.\n",
    "        \n",
    "        :param classList: A list of class names.\n",
    "        :return: The class that occurs with the greatest frequency.\n",
    "        \"\"\"\n",
    "        classCount = {}\n",
    "        for vote in classList:\n",
    "            if vote not in classCount.keys():\n",
    "                classCount[vote] = 0\n",
    "            classCount[vote] += 1\n",
    "    \n",
    "    def createTree(self, dataSet, labels):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # Stop when all classes are equal.\n",
    "        classList = [example[-1] for example in dataSet]\n",
    "        if classList.count(classList[0]) == len(classList):\n",
    "            return classList[0]\n",
    "        # When no more features, return majority.\n",
    "        if len(dataSet[0]) == 1:\n",
    "            return majority\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees = ID3()\n",
    "myDat, labels = trees.createDataSet()\n",
    "myDat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Shannon entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees.calcShannonEnt(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees.splitDataSet(myDat, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'no'], [1, 'no']]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees.splitDataSet(myDat, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best feature to split on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees.chooseBestFeatureToSplit(myDat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
